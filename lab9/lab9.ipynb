{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef4337b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5 Decision Tree:\n",
      " {'Temp': {np.int64(64): 'Yes', np.int64(65): 'No', np.int64(68): 'Yes', np.int64(69): 'Yes', np.int64(70): 'Yes', np.int64(71): 'No', np.int64(72): {'Outlook': {'Overcast': 'Yes', 'Sunny': 'No'}}, np.int64(75): 'Yes', np.int64(80): 'No', np.int64(81): 'Yes', np.int64(83): 'Yes', np.int64(85): 'No'}}\n",
      "\n",
      "Predicted Decision for sample: No\n"
     ]
    }
   ],
   "source": [
    "#-------1.WEATHER DATASET USING C4.5 ALGORITHM-------#\n",
    "\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Create the dataset ---\n",
    "data = {\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast',\n",
    "                'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
    "    'Temp': [85, 80, 83, 70, 68, 65, 64, 72, 69, 75, 75, 72, 81, 71],\n",
    "    'Humidity': [85, 90, 78, 96, 80, 70, 65, 95, 70, 80, 70, 90, 75, 80],\n",
    "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak',\n",
    "             'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong'],\n",
    "    'Decision': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No',\n",
    "                 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# --- Step 2: Entropy calculation ---\n",
    "def entropy(target_col):\n",
    "    elements, counts = np.unique(target_col, return_counts=True)\n",
    "    entropy_val = 0\n",
    "    for i in range(len(elements)):\n",
    "        p = counts[i]/np.sum(counts)\n",
    "        entropy_val += -p * math.log2(p)\n",
    "    return entropy_val\n",
    "\n",
    "# --- Step 3: Information gain ratio ---\n",
    "def info_gain_ratio(data, split_attribute_name, target_name=\"Decision\"):\n",
    "    total_entropy = entropy(data[target_name])\n",
    "    vals, counts = np.unique(data[split_attribute_name], return_counts=True)\n",
    "    \n",
    "    # Weighted entropy\n",
    "    weighted_entropy = 0\n",
    "    for i in range(len(vals)):\n",
    "        subset = data[data[split_attribute_name] == vals[i]]\n",
    "        weighted_entropy += (counts[i]/np.sum(counts)) * entropy(subset[target_name])\n",
    "        \n",
    "    info_gain = total_entropy - weighted_entropy\n",
    "    \n",
    "    # Split info (for gain ratio)\n",
    "    split_info = 0\n",
    "    for i in range(len(vals)):\n",
    "        p = counts[i]/np.sum(counts)\n",
    "        split_info += -p * math.log2(p)\n",
    "        \n",
    "    if split_info == 0:\n",
    "        return 0  # avoid division by zero\n",
    "    gain_ratio = info_gain / split_info\n",
    "    return gain_ratio\n",
    "\n",
    "# --- Step 4: Recursive tree builder (C4.5) ---\n",
    "def c45_build_tree(data, target_name=\"Decision\"):\n",
    "    if len(np.unique(data[target_name])) == 1:\n",
    "        return np.unique(data[target_name])[0]\n",
    "    \n",
    "    if len(data.columns) == 1:\n",
    "        return data[target_name].mode()[0]\n",
    "    \n",
    "    gain_ratios = [info_gain_ratio(data, attr, target_name) for attr in data.columns if attr != target_name]\n",
    "    best_attr = data.columns[:-1][np.argmax(gain_ratios)]\n",
    "    \n",
    "    tree = {best_attr: {}}\n",
    "    \n",
    "    for val in np.unique(data[best_attr]):\n",
    "        sub_data = data[data[best_attr] == val].drop(columns=[best_attr])\n",
    "        subtree = c45_build_tree(sub_data, target_name)\n",
    "        tree[best_attr][val] = subtree\n",
    "        \n",
    "    return tree\n",
    "\n",
    "# --- Step 5: Build and display the decision tree ---\n",
    "import numpy as np\n",
    "tree = c45_build_tree(df)\n",
    "print(\"C4.5 Decision Tree:\\n\", tree)\n",
    "\n",
    "# --- Step 6: Classify a new sample ---\n",
    "def classify(tree, sample):\n",
    "    for key in tree.keys():\n",
    "        value = sample[key]\n",
    "        if value in tree[key]:\n",
    "            if isinstance(tree[key][value], dict):\n",
    "                return classify(tree[key][value], sample)\n",
    "            else:\n",
    "                return tree[key][value]\n",
    "    return None\n",
    "\n",
    "# Example test case\n",
    "sample = {'Outlook': 'Sunny', 'Temp': 72, 'Humidity': 90, 'Wind': 'Weak'}\n",
    "print(\"\\nPredicted Decision for sample:\", classify(tree, sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9808c4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART Decision Tree (dictionary form):\n",
      "{'index': 3, 'value': 'Weak', 'left': {'index': 0, 'value': 'Sunny', 'left': {'index': 1, 'value': 72, 'left': 'No', 'right': 'No'}, 'right': {'index': 0, 'value': 'Overcast', 'left': 'Yes', 'right': 'Yes'}}, 'right': {'index': 0, 'value': 'Overcast', 'left': {'index': 1, 'value': 64, 'left': 'Yes', 'right': 'Yes'}, 'right': {'index': 0, 'value': 'Sunny', 'left': 'No', 'right': 'No'}}}\n",
      "\n",
      "Predicted Decision for sample: No\n"
     ]
    }
   ],
   "source": [
    "#-------2.WEATHER DATASET USING CART ALGORITHM-------#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Dataset ---\n",
    "data = {\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast',\n",
    "                'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
    "    'Temp': [85, 80, 83, 70, 68, 65, 64, 72, 69, 75, 75, 72, 81, 71],\n",
    "    'Humidity': [85, 90, 78, 96, 80, 70, 65, 95, 70, 80, 70, 90, 75, 80],\n",
    "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak',\n",
    "             'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong'],\n",
    "    'Decision': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No',\n",
    "                 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# --- Step 2: Gini impurity ---\n",
    "def gini_impurity(y):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    probs = counts / counts.sum()\n",
    "    return 1 - np.sum(probs ** 2)\n",
    "\n",
    "# --- Step 3: Weighted Gini for a split ---\n",
    "def gini_index(groups, classes):\n",
    "    n_instances = sum([len(group) for group in groups])\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        if len(group) == 0:\n",
    "            continue\n",
    "        size = len(group)\n",
    "        score = 0.0\n",
    "        _, counts = np.unique(group, return_counts=True)\n",
    "        for count in counts:\n",
    "            p = count / size\n",
    "            score += p * p\n",
    "        gini += (1 - score) * (size / n_instances)\n",
    "    return gini\n",
    "\n",
    "# --- Step 4: Split dataset based on attribute and value ---\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = [], []\n",
    "    for row in dataset:\n",
    "        if isinstance(value, (int, float)):  # numeric\n",
    "            if row[index] <= value:\n",
    "                left.append(row)\n",
    "            else:\n",
    "                right.append(row)\n",
    "        else:  # categorical\n",
    "            if row[index] == value:\n",
    "                left.append(row)\n",
    "            else:\n",
    "                right.append(row)\n",
    "    return left, right\n",
    "\n",
    "# --- Step 5: Find the best split ---\n",
    "def get_best_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    best_index, best_value, best_score, best_groups = None, None, 999, None\n",
    "    for index in range(len(dataset[0]) - 1):  # skip target column\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < best_score:\n",
    "                best_index, best_value, best_score, best_groups = index, row[index], gini, groups\n",
    "    return {'index': best_index, 'value': best_value, 'groups': best_groups}\n",
    "\n",
    "# --- Step 6: Create a terminal node value ---\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "# --- Step 7: Recursive split ---\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # check for no split\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_best_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth + 1)\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_best_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth + 1)\n",
    "\n",
    "# --- Step 8: Build the tree ---\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_best_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "# --- Step 9: Make prediction ---\n",
    "def predict(node, row):\n",
    "    if isinstance(row[node['index']], (int, float)):\n",
    "        if row[node['index']] <= node['value']:\n",
    "            if isinstance(node['left'], dict):\n",
    "                return predict(node['left'], row)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'], dict):\n",
    "                return predict(node['right'], row)\n",
    "            else:\n",
    "                return node['right']\n",
    "    else:\n",
    "        if row[node['index']] == node['value']:\n",
    "            if isinstance(node['left'], dict):\n",
    "                return predict(node['left'], row)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'], dict):\n",
    "                return predict(node['right'], row)\n",
    "            else:\n",
    "                return node['right']\n",
    "\n",
    "# --- Step 10: Train the CART tree ---\n",
    "dataset = df.values.tolist()\n",
    "tree = build_tree(dataset, max_depth=3, min_size=1)\n",
    "\n",
    "print(\"CART Decision Tree (dictionary form):\")\n",
    "print(tree)\n",
    "\n",
    "# --- Step 11: Test sample ---\n",
    "test_sample = ['Sunny', 72, 90, 'Weak']  # new record\n",
    "prediction = predict(tree, test_sample)\n",
    "print(\"\\nPredicted Decision for sample:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "395b8d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5 Decision Tree:\n",
      "{'Credit': {'Bad': {'Income': {'High': 'No', 'Low': 'No', 'Medium': 'Yes'}}, 'Good': 'Yes'}}\n"
     ]
    }
   ],
   "source": [
    "#-----3.A.LOAN DATASET-----#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Dataset\n",
    "df = pd.DataFrame({\n",
    "    'Income': ['Low', 'Low', 'Medium', 'Medium', 'High', 'High'],\n",
    "    'Credit': ['Good', 'Bad', 'Good', 'Bad', 'Good', 'Bad'],\n",
    "    'Loan Approved': ['Yes', 'No', 'Yes', 'Yes', 'Yes', 'No']\n",
    "})\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# ðŸ”¹ C4.5 Implementation (Information Gain Ratio)\n",
    "# -----------------------------------------------------------\n",
    "def entropy(col):\n",
    "    elements, counts = np.unique(col, return_counts=True)\n",
    "    entropy_val = 0\n",
    "    for i in range(len(elements)):\n",
    "        p = counts[i]/np.sum(counts)\n",
    "        entropy_val += -p * math.log2(p)\n",
    "    return entropy_val\n",
    "\n",
    "def info_gain_ratio(data, split_attribute_name, target_name=\"Loan Approved\"):\n",
    "    total_entropy = entropy(data[target_name])\n",
    "    vals, counts = np.unique(data[split_attribute_name], return_counts=True)\n",
    "    \n",
    "    weighted_entropy = 0\n",
    "    for i in range(len(vals)):\n",
    "        subset = data[data[split_attribute_name] == vals[i]]\n",
    "        weighted_entropy += (counts[i]/np.sum(counts)) * entropy(subset[target_name])\n",
    "        \n",
    "    info_gain = total_entropy - weighted_entropy\n",
    "    \n",
    "    split_info = 0\n",
    "    for i in range(len(vals)):\n",
    "        p = counts[i]/np.sum(counts)\n",
    "        split_info += -p * math.log2(p)\n",
    "    \n",
    "    if split_info == 0:\n",
    "        return 0\n",
    "    return info_gain / split_info\n",
    "\n",
    "def c45_build_tree(data, target_name=\"Loan Approved\"):\n",
    "    if len(np.unique(data[target_name])) == 1:\n",
    "        return np.unique(data[target_name])[0]\n",
    "    \n",
    "    if len(data.columns) == 1:\n",
    "        return data[target_name].mode()[0]\n",
    "    \n",
    "    gain_ratios = [info_gain_ratio(data, attr, target_name) for attr in data.columns if attr != target_name]\n",
    "    best_attr = data.columns[:-1][np.argmax(gain_ratios)]\n",
    "    \n",
    "    tree = {best_attr: {}}\n",
    "    for val in np.unique(data[best_attr]):\n",
    "        sub_data = data[data[best_attr] == val].drop(columns=[best_attr])\n",
    "        subtree = c45_build_tree(sub_data, target_name)\n",
    "        tree[best_attr][val] = subtree\n",
    "    return tree\n",
    "\n",
    "c45_tree = c45_build_tree(df)\n",
    "print(\"C4.5 Decision Tree:\")\n",
    "print(c45_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3f1a5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CART Decision Tree (dictionary form):\n",
      "{'index': 1, 'value': 'Good', 'left': {'index': 0, 'value': 'Low', 'left': 'Yes', 'right': 'Yes'}, 'right': {'index': 0, 'value': 'Medium', 'left': 'Yes', 'right': 'No'}}\n"
     ]
    }
   ],
   "source": [
    "#3.B. CART Implementation\n",
    "# Gini Impurity\n",
    "def gini_impurity(y):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    probs = counts / counts.sum()\n",
    "    return 1 - np.sum(probs ** 2)\n",
    "\n",
    "def gini_index(groups, classes):\n",
    "    n_instances = sum([len(group) for group in groups])\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        if len(group) == 0:\n",
    "            continue\n",
    "        size = len(group)\n",
    "        score = 0.0\n",
    "        _, counts = np.unique(group, return_counts=True)\n",
    "        for count in counts:\n",
    "            p = count / size\n",
    "            score += p * p\n",
    "        gini += (1 - score) * (size / n_instances)\n",
    "    return gini\n",
    "\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = [], []\n",
    "    for row in dataset:\n",
    "        if row[index] == value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "def get_best_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    best_index, best_value, best_score, best_groups = None, None, 999, None\n",
    "    for index in range(len(dataset[0]) - 1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < best_score:\n",
    "                best_index, best_value, best_score, best_groups = index, row[index], gini, groups\n",
    "    return {'index': best_index, 'value': best_value, 'groups': best_groups}\n",
    "\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_best_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth + 1)\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_best_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth + 1)\n",
    "\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_best_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "dataset = df.values.tolist()\n",
    "cart_tree = build_tree(dataset, max_depth=2, min_size=1)\n",
    "print(\"\\nCART Decision Tree (dictionary form):\")\n",
    "print(cart_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be9482e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C4.5 (scikit-learn) tree:\n",
      "|--- Credit <= 0.50\n",
      "|   |--- Income <= 1.50\n",
      "|   |   |--- class: 0\n",
      "|   |--- Income >  1.50\n",
      "|   |   |--- class: 1\n",
      "|--- Credit >  0.50\n",
      "|   |--- class: 1\n",
      "\n",
      "\n",
      "CART (scikit-learn) tree:\n",
      "|--- Credit <= 0.50\n",
      "|   |--- Income <= 1.50\n",
      "|   |   |--- class: 0\n",
      "|   |--- Income >  1.50\n",
      "|   |   |--- class: 1\n",
      "|--- Credit >  0.50\n",
      "|   |--- class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using scikit learn for both C4.5 and CART\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical data\n",
    "le = LabelEncoder()\n",
    "df_encoded = df.apply(le.fit_transform)\n",
    "\n",
    "X = df_encoded[['Income', 'Credit']]\n",
    "y = df_encoded['Loan Approved']\n",
    "\n",
    "# --- C4.5 approximation (using entropy) ---\n",
    "c45_clf = DecisionTreeClassifier(criterion='entropy')\n",
    "c45_clf.fit(X, y)\n",
    "print(\"\\nC4.5 (scikit-learn) tree:\")\n",
    "print(export_text(c45_clf, feature_names=['Income', 'Credit']))\n",
    "\n",
    "# --- CART (using Gini) ---\n",
    "cart_clf = DecisionTreeClassifier(criterion='gini')\n",
    "cart_clf.fit(X, y)\n",
    "print(\"\\nCART (scikit-learn) tree:\")\n",
    "print(export_text(cart_clf, feature_names=['Income', 'Credit']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b844d533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
