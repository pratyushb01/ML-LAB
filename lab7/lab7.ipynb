{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae23d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phos_a:  0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "Phos=0.6\n",
    "Pday=0.4\n",
    "Pa_hos=0.3\n",
    "Pa_day=0.2\n",
    "\n",
    "#to find Phos_a\n",
    "#formula= Phos_a=Pa_hos*Phos/total\n",
    "\n",
    "\n",
    "Phos_a=Pa_hos*Phos/(Pa_hos*Phos+Pa_day*Pday)\n",
    "print(\"Phos_a: \",Phos_a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a21d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6923076923076923"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bayes_theorem(prior_A, prior_notA, likelihood_given_A, likelihood_given_notA):\n",
    "    # total probability of evidence\n",
    "    evidence = likelihood_given_A * prior_A + likelihood_given_notA * prior_notA\n",
    "    posterior = (likelihood_given_A * prior_A) / evidence\n",
    "    return posterior\n",
    "\n",
    "bayes_theorem(0.6,0.4,0.3,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aeac7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP=0.99\n",
    "FP=0.02\n",
    "P1=0.01\n",
    "P0=0.99 # disease=total-non.diseased\n",
    "bayes_theorem(0.01,0.99,0.99,0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c94b8846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: yes\n",
      "Probabilities: {'no': 0.008199708454810493, 'yes': 0.027117768595041326}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.priors = {}\n",
    "        self.likelihoods = {}\n",
    "        self.classes = []\n",
    "        self.feature_values = {}\n",
    "\n",
    "    def fit(self, data, target_column):\n",
    "        self.classes = data[target_column].unique()\n",
    "        total_samples = len(data)\n",
    "\n",
    "        # Priors\n",
    "        for c in self.classes:\n",
    "            self.priors[c] = len(data[data[target_column] == c]) / total_samples\n",
    "\n",
    "        # Feature likelihoods\n",
    "        features = [col for col in data.columns if col != target_column]\n",
    "        for feature in features:\n",
    "            self.feature_values[feature] = data[feature].unique()\n",
    "            self.likelihoods[feature] = {}\n",
    "\n",
    "            for c in self.classes:\n",
    "                subset = data[data[target_column] == c]\n",
    "                total_c = len(subset)\n",
    "\n",
    "                self.likelihoods[feature][c] = {}\n",
    "                for value in self.feature_values[feature]:\n",
    "                    count = len(subset[subset[feature] == value])\n",
    "                    # Laplace smoothing\n",
    "                    prob = (count + 1) / (total_c + len(self.feature_values[feature]))\n",
    "                    self.likelihoods[feature][c][value] = prob\n",
    "\n",
    "    def predict(self, x):\n",
    "        posteriors = {}\n",
    "        for c in self.classes:\n",
    "            prob = self.priors[c]\n",
    "            for feature, value in x.items():\n",
    "                if value in self.likelihoods[feature][c]:\n",
    "                    prob *= self.likelihoods[feature][c][value]\n",
    "            posteriors[c] = prob\n",
    "        return max(posteriors, key=posteriors.get), posteriors\n",
    "\n",
    "\n",
    "# Example usage\n",
    "data = pd.DataFrame([\n",
    "    [\"<=30\",\"high\",\"no\",\"fair\",\"no\"],\n",
    "    [\"<=30\",\"high\",\"no\",\"excellent\",\"no\"],\n",
    "    [\"31…40\",\"high\",\"no\",\"fair\",\"yes\"],\n",
    "    [\">40\",\"medium\",\"no\",\"fair\",\"yes\"],\n",
    "    [\">40\",\"low\",\"yes\",\"fair\",\"yes\"],\n",
    "    [\">40\",\"low\",\"yes\",\"excellent\",\"no\"],\n",
    "    [\"31…40\",\"low\",\"yes\",\"excellent\",\"yes\"],\n",
    "    [\"<=30\",\"medium\",\"no\",\"fair\",\"no\"],\n",
    "    [\"<=30\",\"low\",\"yes\",\"fair\",\"yes\"],\n",
    "    [\">40\",\"medium\",\"yes\",\"fair\",\"yes\"],\n",
    "    [\"<=30\",\"medium\",\"yes\",\"excellent\",\"yes\"],\n",
    "    [\"31…40\",\"medium\",\"no\",\"excellent\",\"yes\"],\n",
    "    [\"31…40\",\"high\",\"yes\",\"fair\",\"yes\"],\n",
    "    [\">40\",\"medium\",\"no\",\"excellent\",\"no\"]\n",
    "], columns=[\"age\",\"income\",\"student\",\"credit_rating\",\"computer\"])\n",
    "\n",
    "data.to_csv('Computer_NB.csv')\n",
    "data=pd.read_csv('Computer_NB.csv')\n",
    "nb = NaiveBayesClassifier()\n",
    "nb.fit(data, target_column=\"computer\")\n",
    "\n",
    "# Predict example: age=<=30, income=medium, student=yes, credit=fair\n",
    "sample = {\"age\":\"<=30\",\"income\":\"medium\",\"student\":\"yes\",\"credit_rating\":\"fair\"}\n",
    "pred, probs = nb.predict(sample)\n",
    "\n",
    "print(\"Prediction:\", pred)\n",
    "print(\"Probabilities:\", probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64d99abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Text         Tag\n",
      "0                  A great game      Sports\n",
      "1         The election was over  Not sports\n",
      "2              Very clean match      Sports\n",
      "3  A clean but forgettable game      Sports\n",
      "4       It was a close election  Not sports\n",
      "Prediction: Sports\n",
      "Probabilities: {'Sports': 2.7647999999999997e-05, 'Not sports': 5.7175324559303314e-06}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "class NaiveBayesTextClassifier:\n",
    "    def __init__(self):\n",
    "        self.priors = {}\n",
    "        self.word_counts = {}\n",
    "        self.total_words = {}\n",
    "        self.vocab = set()\n",
    "        self.classes = []\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        # lowercase and split into words\n",
    "        return re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "\n",
    "    def fit(self, df, text_col=\"Text\", target_col=\"Tag\"):\n",
    "        self.classes = df[target_col].unique()\n",
    "        total_docs = len(df)\n",
    "\n",
    "        # Initialize counts\n",
    "        for c in self.classes:\n",
    "            self.word_counts[c] = defaultdict(int)\n",
    "            self.total_words[c] = 0\n",
    "\n",
    "        # Priors and likelihoods\n",
    "        for c in self.classes:\n",
    "            subset = df[df[target_col] == c]\n",
    "            self.priors[c] = len(subset) / total_docs\n",
    "\n",
    "            for text in subset[text_col]:\n",
    "                words = self.tokenize(text)\n",
    "                for w in words:\n",
    "                    self.word_counts[c][w] += 1\n",
    "                    self.total_words[c] += 1\n",
    "                    self.vocab.add(w)\n",
    "\n",
    "    def predict(self, text):\n",
    "        words = self.tokenize(text)\n",
    "        scores = {}\n",
    "\n",
    "        for c in self.classes:\n",
    "            # Start with prior probability\n",
    "            prob = self.priors[c]\n",
    "            for w in words:\n",
    "                count = self.word_counts[c][w]\n",
    "                prob *= (count + 1) / (self.total_words[c] + len(self.vocab))  # Laplace smoothing\n",
    "            scores[c] = prob\n",
    "\n",
    "        return max(scores, key=scores.get), scores\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.DataFrame([\n",
    "    [\"A great game\",\"Sports\"],\n",
    "    [\"The election was over\", \"Not sports\"],\n",
    "    [\"Very clean match\", \"Sports\"],\n",
    "    [\"A clean but forgettable game\", \"Sports\"],\n",
    "    [\"It was a close election\", \"Not sports\"]\n",
    "], columns=[\"Text\",\"Tag\"])\n",
    "\n",
    "# Save to CSV\n",
    "train_data.to_csv(\"Sports_NB.csv\", index=False)\n",
    "\n",
    "# Reload\n",
    "train_data = pd.read_csv(\"Sports_NB.csv\")\n",
    "print(train_data)\n",
    "\n",
    "# Train\n",
    "nb = NaiveBayesTextClassifier()\n",
    "nb.fit(train_data, text_col=\"Text\", target_col=\"Tag\")\n",
    "\n",
    "# Test example\n",
    "test_sentence = \"A very close game\"\n",
    "pred, probs = nb.predict(test_sentence)\n",
    "\n",
    "print(\"Prediction:\", pred)\n",
    "print(\"Probabilities:\", probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6537164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python OpenCV kernel",
   "language": "python",
   "name": "opencv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
